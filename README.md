# Advanced Feature Attribution Analysis using SHAP & LIME

This repository contains an endâ€‘toâ€‘end implementation for training an advanced ML model (XGBoost), performing SHAP global & local explanations, and comparing them with LIME.

## ğŸ“Œ Project Structure
```
shap_lime_project/
â”‚â”€â”€ README.md
â”‚â”€â”€ main.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ reports/
â”‚     â””â”€â”€ explanation_report.md
```

## ğŸš€ What This Project Does
- Trains an XGBoost classifier on a chosen Kaggle dataset.
- Computes SHAP global importance + summary plots.
- Generates SHAP force & waterfall plots for selected instances.
- Generates LIME explanations for the same 5 instances.
- Compares SHAP vs LIME consistency + discrepancies.
- Provides bestâ€‘practice guidelines for regulatedâ€‘industry ML interpretation.

## ğŸ§© Dataset Recommendation
Use **â€œGive Me Some Creditâ€** from Kaggle.

Dataset Name (exact):  
`Give Me Some Credit`  
https://www.kaggle.com/datasets/c/GiveMeSomeCredit

Reason: Tabular, imbalance, riskâ€‘based classification, perfect for SHAP attribution.

## ğŸ›  Installation
```
pip install -r requirements.txt
```

## â–¶ï¸ Run
```
python main.py
```
